---
name: "A conversational agent to steer the universe"
description: "Create and extend an existing interface that uses ChatGPT to create commands to control OpenSpace in an immersive dome environment to enable public presentations."
location: "Norrk√∂ping"
period: "Spring 2025"
number_of_students: "1-2"
contact: [ "alebo68", "matbr31" ]

finished: false
skills: [ "OpenSpace", "Visualization", "LLM" ]
---

## About OpenSpace
[OpenSpace](https://openspaceproject.com) is open-source software that aims to visualize the entire known universe in accurate three-dimensional space.  It is mature science visualization software that can be used by anyone to tell stories about the cosmos and our place in it.

## The Project
Science museums increasingly rely on interactive visualization to enhance visitors' engagement and learning. Public spaces are crucial for enhancing learning and public interest as well as promoting science to underserved communities. Interaction facilitates a degree of freedom of exploration, which can tailor the visualization to specific interests of the public. Freedom of exploration alone, however, is not sufficient --- it must be accompanied with proper guidance in the form of storytelling and points of interest.

Within OpenSpace, a user has to ability to explore, among other things, planets, stars, and satellites using a graphical user interface. The software is used in planetariums during guided tours of the universe given to the broad public. While OpenSpace itself is highly interactive, the visitors/audience usually play a passive role in these tours: the guide often follows a script, while a 'pilot' steers the visualization according to the story being narrated.

This project aims to allow novice users to interact with OpenSpace without the use of the graphical user interface and instead be able to use natural language to interact with the software. The idea is to utilize Natural Language Interfaces to facilitate this interaction. With recent developments in Generative Artificial Intelligence and, in particular, Large Language Models, NLIs can now facilitate many visualization tasks that would be tedious by traditional means, including tweaking the data and visuals on-the-fly, tailoring visualization to specific tasks and users, and building narratives accompanied with a matching visualization to explain a topic. These interactions that are enabled by this project should span a wide array of use cases from "Fly my to the Apollo 11 landing site", "Fly to the biggest planet in the solar system", or "Show me the current sea surface temperature on Earth" that combine knowledge of the system with the general knowledge recovery ability provided by Large Language Models.

## Application
Please send an email indicating your interest for this or other thesis works to [emma.broman@liu.se](mailto:emma.broman@liu.se) including your CV/LinkedIn and a Ladok transcript of courses until EOD **October 10**.
Also include an explanation of why you are interested in this specific project. If you are already a pair wanting to work on the thesis together or you are interested in multiple thesis works, a single email will suffice.

Applications are accepted on a rolling basis.
