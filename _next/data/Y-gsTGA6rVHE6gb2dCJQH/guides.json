{"pageProps":{"guides":[{"slug":"getinge","data":{"id":"getinge","name":"Getinge Dome Production","description":"The Getinge dome production was a collaboration between Linköping University and Getinge, a Swedish company that provides technical solutions and products to hospitals and life science institutions. The goal of the project was to create dome movies that featured three different upcoming Getinge products, for an internal launch event that Getinge hosted in Gothenburg in September 2023.","image":"/content/guides/getinge/cardiohelp_patient.png","people":["guser40","erisu46"],"funding":["getinge","visc","wisdome"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h1: \"h1\",\n    p: \"p\",\n    a: \"a\",\n    h2: \"h2\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.h1, {\n      children: \"About\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The Getinge dome production was a collaboration between Linköping University and\\n\", _jsx(_components.a, {\n        href: \"getinge.com\",\n        children: \"Getinge\"\n      }), \", a Swedish company that provides technical solutions and\\nproducts to hospitals and life science institutions.\\nThe goal of the project was to create dome movies that featured three different upcoming\\nGetinge products, for an internal launch event that Getinge hosted in Gothenburg in\\nSeptember 2023.\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Unreal Engine Render Pipeline\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The dome movies where created using Unreal Engine 5 and the new \", _jsx(_components.a, {\n        href: \"/guides/unreal_engine_fisheye_rendering\",\n        children: \"render pipeline\"\n      }), \" that\\nhad just been created by ImmVis and the Wisdome group. The Getinge dome movies\\noffered an opportunity to test this new pipeline at production level, whereas before\\nit had mostly been tested on smaller examples.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"By utilizing the real time rendering capabilities of Unreal Engine 5, the project time\\ncould be greatly reduced due to the immense gains in rendering performance.\\nThe large scale of dome movies, requiring 8k frames at max resolution, would have meant\\nweeks of rendering time with classic rendering pipelines, especially when rendering movies in\\nstereo, as this effectively doubles the amount of frames needed. Thanks to the\\nUnreal Engine render pipeline, the render time could be reduced from weeks to hours.\\nWithout it, a production like this would not have been feasible within the tight time frame given.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"The Getinge Products\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The production was split up into three movies, covering three different Getinge products\\nthat where all launching in the near future.\\nSince all three products could be maintained within the same Unreal Engine project,\\nthe idea was that synergies with reusable assets and an established render pipeline\\ncould make the work more efficient.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Cardiohelp\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        float: \"right\",\n        marginLeft: \"1rem\"\n      },\n      width: \"30%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/getinge/cardiohelp.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.a, {\n        href: \"https://liuonline.sharepoint.com/:v:/s/GetingesamverkanVisualiseringscenterC/EXERnvRu7IJPqOrScwRutSoBuYqRFq4IKrasC0O_aWE0BQ?e=ScsOeV&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZyIsInJlZmVycmFsQXBwUGxhdGZvcm0iOiJXZWIiLCJyZWZlcnJhbE1vZGUiOiJ2aWV3In19\",\n        children: \"Cardiohelp movie\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A machine that can help patients that are suffering from heart- or lung failiure. It pulls blood from the patient that is oxygenated externally and then reintroduced into the patient, temporarly replacing the internal oxygenation process and gives the patient time to recover.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The focus in the movie was on communicating the severity of the situation when the patients heart is failing, and viewing the interactions with Cardiohelp from a new viewpoint, inside the body.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Bioreactor\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        float: \"right\",\n        marginLeft: \"1rem\"\n      },\n      width: \"30%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/getinge/bioreactor.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.a, {\n        href: \"https://liuonline.sharepoint.com/:v:/s/GetingesamverkanVisualiseringscenterC/EU19YBsd4bVFiDz-qW-nPtEB8xK--1MKCWBcsrznNK7mUQ?e=oTobia&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZyIsInJlZmVycmFsQXBwUGxhdGZvcm0iOiJXZWIiLCJyZWZlcnJhbE1vZGUiOiJ2aWV3In19\",\n        children: \"Bioreactor movie\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A controlled environment that allows cells to grow in higher numbers and produce molecules such as antibodies, which can then be extracted and used in medical applications to cure diseases.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The movie focuses on showing the technical feats of the bioreactor, and connecting what the machine does to the impact it can have on cell and antibody growth.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Aquadis\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.a, {\n        href: \"https://example.com\",\n        children: \"Aquadis movie\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"A washer disinfecter for clinical industrial use that cleans, disinfects and steralizes medical tools.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This movie was a bit shorter and server more as a visual showcaseand teaser for the new product.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Storytelling and designing for the Dome Experience\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The goal of the production was to create an experience in the dome that exceeded that of a traditional product visualizations. Movies in a dome environment, especially when utilizing\\n3D stereo effects, are more immersive than regular 2D videos.\\nTo take advantage of this environment, a lot of the scenes where designed to encapsulate the audience, giving the impression that you are inside the movie.\\nThe nature of the dome environment posed several challenges.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Scale of the dome relative to the scene\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        float: \"right\",\n        marginLeft: \"1rem\"\n      },\n      width: \"30%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/getinge/cardiohelp_stereo_error.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"You have to accomodate for the scale of the dome that the video will be shown on when designing the scenes. The dome in Norrköping has a radius of 7 meters, and the one in Gothenburg is even bigger.\\nThis means that objects on screen should not be too close to the camera as this will look strange, especially in stereo. This can be remedied either by ensuring sufficient distance between the objects in the scene and the camera, or by scaling down the camera (the distance between the stereo eyes) which essentially increases the realtive distance to objects. The latter is needed when the objects that you want to show are quite small and you still want to get close to them, such as the Bioreactor or Cardiohelp.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Camera motion\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When deciding camera paths in the dome it is important to never move to fast, as this will make the audience motion sick. This was a limitation for the commercial format that the Getinge movies had, as you want to show as much as possible in as little time as possible, with quick motions and jump cuts.\\nIn some scenes it was possible to move quick, as most of the surrounding scene was black and the feeling was that the objects in the scene were moving, while more crowded scenes limitied us to slower camera motion.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Special assets and techniques\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"There are some systems and assets that used special techniques to bring life to assets.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Morph target animations\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Several assets where animated using morph target animation to deform the assets.\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"The fluid in the bioreactor, as the water level rises due to the propeller motion\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"The heart and lungs in Cardiohelp\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"The cannula entering the heart in Cardiohelp\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Particle systems\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        float: \"right\",\n        marginLeft: \"1rem\"\n      },\n      width: \"40%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/getinge_primodial_soup_fisheye_example.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To create some effect in the movies, particle systems where used.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The red blood cells traveling through the tubing in Cardiohelp where animated using a particle system which simulated the cells positions along a spline.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The cells in the Bioreactor movie where simulated with a particle system consisting of three different emitters.\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Cells\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Splitting cells\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Antibodies\\nThis allowed us to control the amount of each types during the shot, such that more splitting occured at good pH levels, and that only antibodies remained and lumped together in the end.\\nThe cell splitting animation was done in Blender and imported into UE as an Alembic Geometry Cache, that could be played in a particle system.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Stitching and Ray Traced materials\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Since Fisheye images are created using stitched images, it is important that materials etc are not view dependent as this would cause discrepancies at the stitch edges. This becomes apparet if highly reflective materials such as metal are using screen space reflection. This is solved by setting reflections to use ray tracing. In this project  issues with glass and other transparent materials were also noted, as refraction was also screen space by default. This could also be solved by using ray traced refraction. All uses of ray tracing impacts performance, but since performance is not a big issue when rendering, compared to real time applications, this was not a great concern for this project.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Animated materials\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        float: \"right\",\n        marginLeft: \"1rem\"\n      },\n      width: \"50%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/getinge/bioreactor_fluid_surface.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Many effect in the movie was done by animating materials over time.\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"The pulsating motion of the walls in the heart atrium was achieved by displacing the world postion of the mesh verticies with a wave pattern material.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"The rotational motion of the fluid in the bioreactor was done by rotating the texture coordinates in the surface material.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"The blood in the tubes and in the oxigenator (as seen from outside) where animated using masks and moving a threshold for how much of the material would be affected by the mask. For the tubing, this required proper UV mapping such that the coordinated where running from start to end of the tube.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"UI video material\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        float: \"right\",\n        marginLeft: \"1rem\",\n        marginBottom: \"2rem\"\n      },\n      width: \"50%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/getinge/bioreactor_UI.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The UI in the bioreactor movie was done by animating the UI elements externally in Blender, which was then rendered out into a video. The video was then imported into Unreal Engine and brought into the scene through a media material which was added to a plane in the scene. The video could then be played and controller through the render sequence.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{"id":"getinge","name":"Getinge Dome Production","description":"The Getinge dome production was a collaboration between Linköping University and Getinge, a Swedish company that provides technical solutions and products to hospitals and life science institutions. The goal of the project was to create dome movies that featured three different upcoming Getinge products, for an internal launch event that Getinge hosted in Gothenburg in September 2023.","image":"./cardiohelp_patient.png","people":["guser40","erisu46"],"funding":["getinge","visc","wisdome"]},"scope":{}},"mdxPath":"content/guides/getinge/getinge.mdx"},{"slug":"unreal_engine_fisheye_rendering","data":{"id":"unreal_engine_fisheye_rendering","name":"Unreal Engine Fisheye Rendering","description":"A guide on how to use the Fisheye Render Setup plugin for Unreal Engine to render out fisheye images for usage in dome environment.","image":"/content/guides/unreal_engine_fisheye_rendering/getinge_primodial_soup_fisheye_example.png","people":["guser40"],"funding":["wisdome"]},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h1: \"h1\",\n    p: \"p\",\n    a: \"a\",\n    ul: \"ul\",\n    li: \"li\",\n    ol: \"ol\",\n    h2: \"h2\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.h1, {\n      children: \"About\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        float: \"right\",\n        marginLeft: \"1rem\"\n      },\n      width: \"25%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/stitch_example.png\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This page is a step by step instruction on how to use the Fisheye Render Setup plugin for Unreal Engine to render frames that can be stitched into a fisheye format using out custom \", _jsx(_components.a, {\n        href: \"example.com\",\n        children: \"stitcher\"\n      }), \"\\nThe plugin allows you take a Camera Sequence in Unreal and render out modified Camera Angles of it, creating Left, Right, Top and Bottom frames in stereo that can then be stitched into Fisheye frames.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Using Unreal Engine with it's real time capabilities to render can speed up production time of movies immensly, as dome movie render times can be reduced from weeks and months to hours and days.\"\n    }), \"\\n\", _jsx(\"h1\", {\n      id: \"download-links\",\n      children: \"Download the Unreal Engine plugin\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"/content/guides/unreal_engine_fisheye_rendering/FisheyeRenderSetup_5_0.zip\",\n          children: \"5.0\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"/content/guides/unreal_engine_fisheye_rendering/FisheyeRenderSetup_5_1.zip\",\n          children: \"5.1\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"/content/guides/unreal_engine_fisheye_rendering/FisheyeRenderSetup_5_2.zip\",\n          children: \"5.2\"\n        })\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Making a New Project\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Create a new project. You can use any of the premade templates that suit your project the best, but for this tutorial we will use a blank project.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Make sure you have the following settings in your project. It should be the default settings, with the addition of turning on raytracing\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"50%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_project_settings.png\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Project Settings\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"If your computer supports it, turn on Use Hardware Ray Tracing when available\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Set Ray Lighting Mode to Hit Lighting for reflections\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Installing the Unreal Engine Plugin\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.a, {\n          href: \"#download-links\",\n          children: \"Download the plugin\"\n        }), \" matching your Unreal Engine version\"]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Add the FisheyeRenderSetup folder to your projects Plugins folder. If you don’t have a Plugins folder you can add one.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Start your project and check the Plugins browser to see that the plugin is installed\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Open the Settings menu in your Content Browser and enable Show Plugin Content\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"You can now find the FisheyeRenderSetup content folder under All > Plugins\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Right click LevelSequenceAssetAction and select Run Editor Utility Blueprint to ensure that it can be run further down the line.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_content.png\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Level Setup\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The following steps assumes that you have a blank scene with nothing in it.\\nYou can copy the DomeFisheyeTemplateLevel and use it as a starting point if you want to skip the following setup steps in Light Setup, Post Process Volume and Camera Rig.\\nAlternativly, you could copy and paste the relevant actors into another level.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Lighting\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Go to the Window tab and Open Environment Light Mixer\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Press every button EXCEPT Atmospheric Light 1\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"In the outliner, select the Skylight and turn on the Real Time Capture checkbox\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_light_setup.png\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Post Process Volume\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Add a Post Process Volume to your scene\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Check Infinite Extent (Unbound) so that the volume affects the whole scene\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_ppv_unbound.png\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"3\",\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"Change the reflection method to Standalone Ray Traced (Deprecated). This sets the reflection method to Hardware instead of software.\\nLumen is limited in how good reflections it can produce, especially on highly reflective materials.\\nLumen cheats by using Screen space reflections, but this doesn’t work for fisheye renders as objects visible in one camera won’t reflect in the others.\\nWith Hardware Ray Tracing we get around this problem, with the trade-off being higher rendering time. You can omit this step if you don’t have any issues with reflections.\"\n        }), \"\\n\", _jsx(_components.p, {\n          children: \"a) Tweak Max Roughness to set how reflective a material has to be to get a reflection. Lower values include more objects.\"\n        }), \"\\n\", _jsx(_components.p, {\n          children: \"b) Increase Max Bounces to get a more correct reflection. This is costly, so don’t go higher than you need.\"\n        }), \"\\n\", _jsx(_components.p, {\n          children: \"c) Increase Samples Per Pixels if your reflective surfaces seem grainy. Higher values will be more costly, as it will cast a ray through each pixel for each level.\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"You need to turn off some screen space effects as they don’t work with fisheye stitching. If you have them turned on you will see borders between the stitched images.\"\n        }), \"\\n\", _jsx(_components.p, {\n          children: \"a) Set Bloom > Intensity to 0.0\"\n        }), \"\\n\", _jsx(\"img\", {\n          style: {\n            display: \"block\",\n            margin: \"auto\"\n          },\n          width: \"80%\",\n          alt: \"Absolute image\",\n          src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_ppv_bloom.png\"\n        }), \"\\n\", _jsx(_components.p, {\n          children: \"b) Set Image Effects > Vignette Intensity to 0.0\"\n        }), \"\\n\", _jsx(\"img\", {\n          style: {\n            display: \"block\",\n            margin: \"auto\"\n          },\n          width: \"80%\",\n          alt: \"Absolute image\",\n          src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_ppv_vignette.png\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsx(_components.p, {\n          children: \"Unreal Engine has Auto Exposure turned on by default (you can also edit this in project settings). We want to turn this of as the exposure should not change between camera angles.\"\n        }), \"\\n\", _jsx(_components.p, {\n          children: \"a) Set Exposure > Metering Mode to Manual\"\n        }), \"\\n\", _jsx(_components.p, {\n          children: \"b) Exposure > Turn Apply Physical Camera Exposure Off\"\n        }), \"\\n\", _jsx(_components.p, {\n          children: \"c) Tweak Exposure > Exposure Compensation to match the lighting you want in your scene\"\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Camera Rig\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"We will now create a camera rig that matches the dome we want to render to. The goal is to create a Camera Transform Actor that we control in the animation, and attaching a camera to it that will be static, but with a different rotation for each camera angle.\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Add an actor into the level. Name this actor CameraTransform\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Add another actor and name it DomeTilt. Attach DomeTilt to CameraTransform and set its relative rotation to (0, 63, 0). Make sure the other transforms are at default values.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Add a CameraActor to the level and attach it to DomeTilt. If you want you can set the relative rotation to (0, -63, 0) to make the camera face forward for preview purposes. Make sure the other transforms are at default values. Set the cameras Aspect Ratio to 1.0 and Post Process Blend Weight to 0.0.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Dome Preview\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If you want you can also add a Dome Preview, to check how the fisheye view would look in a dome\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Go to All > Plugins > FisheyeRenderSetup Content > DomePreview\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Add a DomePreviewSphere. You can set the dome to be either 180° or 165°, as well as set the dome tilt angle\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Add a DomePreviewCamera. Attach it to DomeTilt and make sure the transforms are at default values.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Select the DomePreviewCamera and press the Update Camera button in the Details menu. The camera view will now be drawn to the DomePreviewSphere.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"You can also check Capture Every Frame to have the camera always update but beware of the performance hit.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Creating Sequences\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To render out a scene, you need to create sequences that you can render out using the Movie Render Queue.\\nThe goal is to create a base sequence, and then create duplicates with the adjusted camera angles needed to render out the images we use for stitching together fisheye images.\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Create a new Level Sequence and open it.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Select the CameraActor from your rig and drag it into Sequence. You should see it be added as a new track, along with a Camera Cuts track.\\nYou can also manually create a Camera Cuts track and add your camera to it.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Drag in the CameraTransform actor and add a Transform track to it. Add keyframes to CameraTransform’s transform to animate your camera.\\nYou need to add at least one keyframe to keep it in place, even if you plan to have a static camera. (IMPORTANT! Do not add keyframes to the CameraActor.\\nIt should remain static as we change it for the camera angles). You could alternatively animate the camera and other objects in a separate sequence and add it as a Subsequence.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_sequence_keyframe.png\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"4\",\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"If the camera gets too close to an object, the stereo effect will break as the brain can't parse what's going on. Bascially, if the dome surface is 7 meters away, you get a good stereo effect of an object that is 5 meters away. But if the object is 50 cm away, the stereo will be too intese and it will make you naseus.\\nIf this is the case you might want to adjust the distance between your eyes instead, effectivly scaling the user. If you scale down the viewer to 1/10th, 50 cm becomes 5 meters in the eyes of the viewer.\\nTo achive this in Sequencer, you can keyframe the scale of any parent above the CameraActor in hierarchy. This means that the relative location of CameraActor in relation to its parent will be scaled, so the normal \\\"eye distance\\\" of 3.5 cm will be 0.35 at 1/10th scale etc.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Creating Camera Angle Duplicates\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Once you have a base Level Sequence, you want to create duplicates for each camera angle, as well as eye of you are rendering for stereo. To do this we use scripted functionality from the plugin.\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Right click your Level Sequence and select Scripted Asset Action > Make Duplicates with Fisheye Camera Angles\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_sequence_keyframe.png\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"2\",\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Now you should see a new folder appearing, containing the new duplicates. The prefix indicates which eye position and camera angle each Sequence contains. E.g. LB_Sequence is Left eye, Bottom camera angle.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_sequence_duplicates.png\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"3\",\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Before you render you should check that the new camera angles are correct. If something seems of, make sure to check in the base sequence that you have assigned a keyed value to CameraTransform,\\nand that the CameraActor has no keys.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"If you want to adjust your sequence, make the adjustments in the base Sequence and then redo the duplication step. It should override the old duplicates.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Render with Movie Render Queue\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"It is now time to render your sequences. This is done with the Movie Render Queue\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Open Window > Cinematics > Movie Render Queue.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Drag one of the sequences from the Content Browser into the Movie Render Queue\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Open the settings and press Load/Save Pre-set. Select the RenderSettings pre-set which is part of the plugin. Press Accept to apply the new settings.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"You can now drag in the rest of the sequences, and RenderSettings should apply to all of them.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_mrq.png\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"5\",\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"If you want to change something in RenderSettings, you can either change it locally for one sequence in the Movie Render Queue window or change it globally by opening the RenderSettings file in the plugin folder.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"a) In the Output tab you can control various settings, such as where the frames will be saved and under what name, the resolution of your frames and if you want to render a custom set of frames.\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_mrq_output.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"b) If your desired render resolution is higher than what your computer can manage, you can use the settings in the High Resolution tab to set a tile count which will split each frame into smaller tiles. E.g. if you set the tile count to 4, it will split a 4096x4096 image into 4x4 1028x1028 images, which can be rendered on a far less powerful computer. However, if you can manage high resolutions right away it is most likely quicker to render.\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_mrq_high_res.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"c.\\tShould you choose to use High Resolution, you will also need to adjust settings in Anti-Aliasing. Set the anti-aliasing method to none, as it is not supported for tiled rendering. Instead, you use Temporal Samples to remove any aliasing issues. This creates a number of subframes based on your TS count, captured with a small time difference, which can be averaged to produce a more clean end frame. Increase the count as you see fit to remove any artifacts that may occur, at the cost of higher render times.\"\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_mrq_anti_alias.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Be aware that the use of High Resolution/Anti-Alising might cause GPU crashes when used together with Hardware Ray Tracing. This behavior has been observed in Unreal Engine 5.1/5.2 and seems to be a bug that has been reported to Epic Games. The problem should be resolved in future updates, but an alternative is to use 5.0 where this bug doesn't exist.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Niagara Systems\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"As the rendering basically restarts for each camera angle, the scene will simulate again for each render. This means that things like Niagara Particle systems can’t have a random factor,\\nas it needs to produce the same result for each render.\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"In your Niagara Emitter/System, make sure that Emitter > Determinism is checked to ensure the same result each render\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_niagara_determinism.png\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"2\",\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"We can control the Niagara System by adding it to our Sequence. Add a Niagara Component track and add a System Life Cycle track to it.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_niagara_life_cycle_track.png\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"3\",\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Right click the Life Cycle track and set Properties > Age Update Mode to Desired Age. This makes the sequencer control the life span of the particle system, allowing you to scrub though the simulation with a\\ndetermined state for each frame.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_niagara_life_cycle_properties.png\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Making Procedural Materials Deterministic\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Some Materials changes with time and other variables that might vary between runs. As this might cause issues with rendering multiple times, we need a deterministic solution. Therefore, you might want to use a Global Material Collection to control a material with the sequencer.\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Create a Materials > Global Parameter Collection and open it up.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Add any values that you might want to change globally. They can be both scalar and vector parameters.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Drag your GPC into a material and select your parameter of choice from the dropdown in the Details menu.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Plug the value in as needed, e.g. as the Time input for a Panner node.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_material_global_param.png\"\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"5\",\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Drag your GPC into a sequencer and add the parameter you want to control as a track.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Set keyframes for the parameter and watch as your material changes when playing the sequence.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(\"img\", {\n      style: {\n        display: \"block\",\n        margin: \"auto\"\n      },\n      width: \"80%\",\n      alt: \"Absolute image\",\n      src: \"/content/guides/unreal_engine_fisheye_rendering/fisheye_plugin_material_global_param_track.png\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{"id":"unreal_engine_fisheye_rendering","name":"Unreal Engine Fisheye Rendering","description":"A guide on how to use the Fisheye Render Setup plugin for Unreal Engine to render out fisheye images for usage in dome environment.","image":"./getinge_primodial_soup_fisheye_example.png","people":["guser40"],"funding":["wisdome"]},"scope":{}},"mdxPath":"content/guides/unreal_engine_fisheye_rendering/unreal_engine_fisheye_rendering.mdx"}]},"__N_SSG":true}