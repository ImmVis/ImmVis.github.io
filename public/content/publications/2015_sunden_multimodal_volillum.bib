@article{SUNDEN201547,
  title = {Multimodal volume illumination},
  journal = {Computers & Graphics},
  volume = {50},
  pages = {47-60},
  year = {2015},
  issn = {0097-8493},
  doi = {https://doi.org/10.1016/j.cag.2015.05.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0097849315000515},
  author = {Erik Sundén and Sathish Kottravel and Timo Ropinski},
  keywords = {Volume rendering, Volumetric illumination, Multimodal visualization},
  abstract = {Despite the increasing importance of multimodal volumetric data acquisition and the recent progress in advanced volume illumination, interactive multimodal volume illumination remains an open challenge. As a consequence, the perceptual benefits of advanced volume illumination algorithms cannot be exploited when visualizing multimodal data – a scenario where increased data complexity urges for improved spatial comprehension. The two main factors hindering the application of advanced volumetric illumination models to multimodal data sets are rendering complexity and memory consumption. Solving the volume rendering integral by considering multimodal illumination increases the sampling complexity. At the same time, the increased storage requirements of multimodal data sets forbid to exploit precomputation results, which are often facilitated by advanced volume illumination algorithms to reduce the amount of per-frame computations. In this paper, we propose an interactive volume rendering approach that supports advanced illumination when visualizing multimodal volumetric data sets. The presented approach has been developed with the goal to simplify and minimize per-sample operations, while at the same time reducing the memory requirements. We will show how to exploit illumination-importance metrics, to compress and transform multimodal data sets into an illumination-aware representation, which is accessed during rendering through a novel light-space-based volume rendering algorithm. Both, data transformation and rendering algorithm, are closely intervened by taking compression errors into account during rendering. We describe and analyze the presented approach in detail, and apply it to real-world multimodal data sets from biology, medicine, meteorology and engineering.}
}